{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63144278-9e9a-42e8-9057-6272126c2162",
   "metadata": {},
   "source": [
    "# STAGE 3a: PROCESS - Save cleaned CSV files\n",
    "\n",
    "Loop Through csv files and Save the cleaned csv in./data/cleaned_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5073a-2aef-4fcc-a5bd-a80f777b6d91",
   "metadata": {},
   "source": [
    "This notebook is to run the code from Clean by month. We will iterate through the file list stored in <font color ='red'> file_list_2020.csv</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a7b6b4-8764-48de-bd64-5bbbce7d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import datetime\n",
    "\n",
    "file_list_df = pd.read_csv('file_list_2020.csv', header=None, names= ['filename'])\n",
    "file_list = file_list_df['filename'].values\n",
    "\n",
    "dtypes = {'ride_id': 'str', 'rideable_type': 'category', 'start_station_name': 'category', 'start_station_id': 'category', 'end_station_name':'category',\n",
    "           'end_station_id': 'category', 'member_casual':'category'}\n",
    "\n",
    "# this is a function to read the trip files, keep in mind I hard coded the dates columns\n",
    "def read_csv_to_df(filename, dtype):\n",
    "    df = pd.read_csv('./Data/csv/'+filename, parse_dates=['started_at','ended_at'], dtype = dtype)\n",
    "\n",
    "    return df\n",
    "\n",
    "# # this file is a random choice\n",
    "#filename = file_list[3]\n",
    "## Here we make a loop with the file_list\n",
    "for filename in file_list[3:]:\n",
    "    \n",
    "    df = read_csv_to_df(filename, dtypes)\n",
    "    \n",
    "    ### Drop rows with null data\n",
    "\n",
    "    rows_to_delete_na = df[df.isnull().any(axis=1)==True].index\n",
    "    #print (filename, ' rows_to_delete_na',len(rows_to_delete_na))\n",
    "\n",
    "    df = df[~df.index.isin(rows_to_delete_na)]\n",
    "\n",
    "\n",
    "    ### Drop rows with time end less than time start\n",
    "\n",
    "    rows_to_delete_timenegative = df[(df['ended_at']<df['started_at'])].index\n",
    "    #print (filename, 'rows_to_delete_timenegative',len(rows_to_delete_timenegative))\n",
    "\n",
    "    df = df[~df.index.isin(rows_to_delete_timenegative)]\n",
    "\n",
    "\n",
    "    ## Observing lat long consistency per station id\n",
    "    ## Check latitude numbers associated with each station id.\n",
    "\n",
    "    \n",
    "    # first concatenate start and stop stations to check outliers together\n",
    "    df_lat_eval_start_station = df[['start_station_id','start_lat']].rename(columns={\"start_station_id\": \"station_id\", \"start_lat\": \"station_lat\"})\n",
    "    df_lat_eval_end_station = df[['end_station_id','end_lat']].rename(columns={\"end_station_id\": \"station_id\", \"end_lat\": \"station_lat\"})\n",
    "    df_lat_eval = pd.concat([df_lat_eval_start_station,df_lat_eval_end_station],axis=0)\n",
    "    df_lat_eval.reset_index(inplace=True)\n",
    "    df_lat_eval.columns = ['index_orig', 'station_id', 'station_lat']\n",
    "\n",
    "\n",
    "    # try to find outliers for latitude number for each station id# delete rows with latitude number that is not consistent with the station id\n",
    "\n",
    "    # the number of samples should be greater than 30 for relevant zscore calculation\n",
    "    c = df_lat_eval.groupby(['station_id'])['station_id'].count()\n",
    "    few_samples_station_ids= c[c<30].index\n",
    "    df_lat_eval.drop(df_lat_eval[df_lat_eval['station_id'].isin(few_samples_station_ids)].index, inplace=True)\n",
    "\n",
    "    # calculate z score using groupby station_id\n",
    "\n",
    "    df_zscore_lat = df_lat_eval.groupby(['station_id'])['station_lat'].transform(lambda x : zscore(x,ddof=1))\n",
    "    df_zscore_lat.name = 'zscore'\n",
    "\n",
    "    df_lat_eval_zscore = pd.concat([df_lat_eval,df_zscore_lat],axis=1)\n",
    "    rows_to_delete_lat = df_lat_eval_zscore[(df_lat_eval_zscore['zscore']<-3)|(df_lat_eval_zscore['zscore']>3)]\n",
    "    rows_to_delete_list_lat=list(rows_to_delete_lat['index_orig'])\n",
    "\n",
    "    # use the same code to run on longitude\n",
    "\n",
    "    df_lng_eval_start_station = df[['start_station_id','start_lng']].rename(columns={\"start_station_id\": \"station_id\", \"start_lng\": \"station_lng\"})\n",
    "    df_lng_eval_end_station = df[['end_station_id','end_lng']].rename(columns={\"end_station_id\": \"station_id\", \"end_lng\": \"station_lng\"})\n",
    "    df_lng_eval_start_station['start_end'] = 'start'\n",
    "    df_lng_eval_end_station['start_end'] = 'end'\n",
    "    df_lng_eval = pd.concat([df_lng_eval_start_station,df_lng_eval_end_station],axis=0)\n",
    "    df_lng_eval.reset_index(inplace=True)\n",
    "    df_lng_eval.columns = ['index_orig', 'station_id', 'station_lng', 'start_end']\n",
    "\n",
    "    c = df_lng_eval.groupby(['station_id'])['station_id'].count()\n",
    "    few_samples_station_ids= c[c<30].index\n",
    "    few_samples_station_ids # exclude these station ids\n",
    "    df_lng_eval.drop(df_lng_eval[df_lng_eval['station_id'].isin(few_samples_station_ids)].index, inplace=True)\n",
    "\n",
    "    df_zscore_lng = df_lng_eval.groupby(['station_id'])['station_lng'].transform(lambda x : zscore(x,ddof=1))\n",
    "    df_zscore_lng.name = 'zscore'\n",
    "    df_lng_eval_zscore = pd.concat([df_lng_eval,df_zscore_lng],axis=1)\n",
    "    rows_to_delete_lng = df_lng_eval_zscore[(df_lng_eval_zscore['zscore']<-3)|(df_lng_eval_zscore['zscore']>3)]\n",
    "\n",
    "    rows_to_delete_list_lng=list(rows_to_delete_lng['index_orig'])\n",
    "\n",
    "    ### It is very possible the station names with (Temp) are for testing only\n",
    "    # The rows that contain station name with Temp ought to be deleted\n",
    "\n",
    "    rows_to_delete_temp = list(df[df['start_station_name'].str.contains(\"Temp\")].index)\n",
    "\n",
    "    ### Now do the final clean up by deleting rows with lat/lng outlier, and with temp stations\n",
    "\n",
    "    rows_to_drop = list(set(rows_to_delete_list_lat) | set(rows_to_delete_list_lng) | set(rows_to_delete_temp) )\n",
    "    df = df[~df.index.isin(rows_to_drop)]\n",
    "\n",
    "    ### Calculate trip duration and examine outliers\n",
    "\n",
    "\n",
    "\n",
    "    duration  = (df['ended_at']-df['started_at']).apply(datetime.timedelta.total_seconds)\n",
    "\n",
    "    duration.name ='duration'\n",
    "\n",
    "    duration_zscore_calc = ((duration - duration.mean())/duration.std())\n",
    "\n",
    "    duration_outliers = duration[(duration_zscore_calc>3) | (duration_zscore_calc<-3)]\n",
    "\n",
    "    rows_to_delete_duration = duration_outliers.index\n",
    "\n",
    "    df = df[~df.index.isin(rows_to_delete_duration)]\n",
    "\n",
    "\n",
    "    ### Collect all the index of all the deleted rows and output as csv for record\n",
    "\n",
    "    rows_deleted = list(set(rows_to_delete_na) |\\\n",
    "                        set(rows_to_delete_timenegative)|\\\n",
    "                        set(rows_to_delete_duration)|\\\n",
    "                        set(rows_to_delete_list_lat) | \\\n",
    "                        set(rows_to_delete_list_lng) | \\\n",
    "                        set(rows_to_delete_temp) ) \n",
    "\n",
    "    file_dest = './data/deleted_rows/row_deleted_for_'+filename\n",
    "\n",
    "    pd.DataFrame(rows_deleted).to_csv(file_dest)\n",
    "\n",
    "    df.to_csv('./data/cleaned_csv/'+filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e6d50-bb70-4c4b-9382-02b9226ff693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclistic_kernel",
   "language": "python",
   "name": "cyclistic_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
